---
title: "Test RL on synthetic data using uncertain delay"
output: html_notebook
---

Katie Gostic + Phil Arevalo

```{r asis = T}
cat(sprintf('\n## Last run %s', Sys.Date()))
```
```{r}
## Preamble
rm(list = ls())
library(ggplot2)
library(dplyr)
library(tidyr)
library(readr)
library(cowplot)
library(EpiEstim)
theme_set(theme_bw())
knitr::opts_chunk$set(message = FALSE)
parlist <- read_rds('../examples_syndat/true_pars.rds')
source('../code/util.R')
source('../code/cori.R')
if(!dir.exists('figs')){dir.create('figs')}
```

## Extract SEIR simulation and plot.

- Incidence here is observed at time of infection (S -> E).
- SEIR simulation is deterministic

```{r}
setwd('../examples_syndat/')
get_sim_df() %>%
    filter(time < 300) %>%
ggplot() +
  geom_line(aes(x = time, y = incidence))+
  geom_vline(aes(xintercept = parlist$intervention_time_1), lty = 2)+ ## Dahsed line where Rt starts to decrease
    geom_vline(aes(xintercept = parlist$intervention_time_2), lty = 2)+ ## Dahsed line where Rt starts to decrease
  ggtitle('Epidemic curve') -> inc

get_sim_df() %>% 
  filter(time < 300) %>%
  ggplot()+
  geom_line(aes(x = time, y = true_rt)) +
  geom_hline(aes(yintercept = 1), lty = 2)+
  ylab(expression(paste(R[t])))+
  ggtitle(expression(paste('Underlying ', R[t], ' values'))) -> R0

cowplot::plot_grid(R0, inc, align = 'hv', nrow = 2)

sim_df <- get_sim_df()
```


# Fig. 2 - estimate Rt in real time using three different methods, assuming perfect observation at the moment of infection.

## Truncate the synthetic data to a maximum time of observation

```{r}
mt <- 150
source('../code/infer_times_of_infection_observation.R')

## Get death delay distribution
delay_posterior <- read_rds('../data/fitted_delays/delay_infection_to_death_posterior.rds') %>%
  bind_cols()

# obs_delay_dist <- (function(nn){
#   rgamma(nn, 5.8, scale = .95) + ## Incubation from Lauer et al
#   rgamma(nn, 3.5, scale = 2) ## Arbitrary obs delay
# })

obs_delay_dist <- (function(nn){
  rlnorm(n = nn, meanlog = 1, sdlog = .5)
})


get_tObs_from_tInf(n_dS = sim_df$incidence, times = sim_df$time, r_delay_dist = obs_delay_dist, return_times = T)

rtdf <-  merge(
  sim_df %>% select(time, incidence, true_rt),
  get_tObs_from_tInf(n_dS = sim_df$incidence, 
                     times = sim_df$time, 
                     r_delay_dist = obs_delay_dist, 
                     return_times = T) %>% rename(delayed = n),
  by = 'time') %>%
  filter(time <= mt)



p_obs <- .5
## Down sample observed time series
rtdf$obs = sapply(rtdf$delayed, FUN = function(NN) rbinom(n=1, size = NN, prob = p_obs))
```


```{r}
rtdf %>%
  select(time, incidence, obs, delayed) %>%
  mutate(shifted_obs = lead(obs, n = mean(obs_delay_dist(10000)))) %>%
  pivot_longer(-time) %>%
  ggplot()+
  geom_line(aes(x = time, y = value, color = name)) +
  scale_color_manual('', values = c('black', 'green', 'dodgerblue', 'magenta')) +
  theme(legend.position = c(.8, .8)) +
  ylab('daily count') 
```

# 1. Bootstrap the observed time series

** TO DO **

# 2. Sample across uncertainty in the delay distribution
```{r}
## Delay follows a lognormal
## Sample parameters from the posterior

```

# 3. Perform RL deconvolution using the bootstrapped observations and delay distributions
```{r}
source('../code/Richardson_Lucy.R')
ff <- function(xx, mu, sigma){xx*dlnorm(xx, mu, sigma)}

get_discrete_lognormal <- function(k, mu, sigma){
  
  sapply(X = k, FUN = function(k, mu, sigma){
  (1+k)*plnorm(k+1, mu, sigma) -
    2*k*plnorm(k, mu, sigma) +
    (k-1)*plnorm(k-1, mu, sigma)+
    integrate(f = ff, lower = k-1, upper = k, mu = mu, sigma = sigma)$value-
    integrate(f = ff, lower = k, upper = k+1, mu = mu, sigma = sigma)$value
  }, mu = mu, sigma = sigma)
}


deconvolve <- function(obs,  ## Vector of counts per day
                              times = NULL,  ## Optional numeric vector of times
                              delay_posterior,
                              delay_type = 'lognormal',
                       nboot
                              ){
  ## Check inputs
  if(length(times) == 0){
    times = 1:length(obs)
  }
  stopifnot(length(times) == length(obs))
  stopifnot(is.numeric(times))
  stopifnot(delay_type == 'lognormal')
  
  ## Sample nboot delay parameters
  spars <- delay_posterior %>%
    slice(sample(1:nrow(delay_posterior), size = nboot, replace = T))
  
  mapply(FUN = function(mm, ss){
    get_RL(observed = obs, 
           times = times, 
           p_delay = get_discrete_lognormal(k = 0:(length(obs)-1), mu = mm, sigma = ss)) %>%
        filter(time >= 0)
  }, 
  mm = spars$mu, ss = spars$sigma, SIMPLIFY = FALSE)
  
}

decon <- deconvolve(rtdf$obs, delay_posterior = delay_posterior, nboot = 100) 


decon %>%
  bind_rows(.id = 'rep') %>%
  ggplot() +
  geom_line(aes(x = time, y = RL_result, group = rep), alpha = .3) +
  geom_line(data = rtdf,
            aes(x = time, y = incidence), color = 'red') +
    geom_line(data = rtdf,
            aes(x = time, y = obs), color = 'blue')
```




## Function to estimate total infections given a fixed probability of observation
```{r}
est_total_inf <- function(df, ## Data frame containing a column with daily observations
                          p_obs, ## Vector of observation probabilities, one entry for each observation. If you provide a single number, assumes constant observation probability
                          obs_colname, ## Name of the column holding the observations
                          n_replicates = 1) ## Number of times to resample total infections 
  {
  draw_one_sample <- function(k, p){
    # adjust observations to work with negative binomial, i.e., case with 0 observations
    adjusted_k = replace(k, k==0, 0.1)
    
    # Draw a negative binomial sample
    observations = round(mapply(rnbinom, 1, adjusted_k, p) + adjusted_k)
    as.numeric(observations)
  }
  
  obs = df %>% select(obs_colname) %>% unlist(use.names = F)
  
  ## For each entry in the observations column, upscale
  infection_samples = replicate(n = n_replicates, draw_one_sample(obs, p_obs))

  colnames(infection_samples) = paste0('infections.', 1:n_replicates)
  bind_cols(df, as.data.frame(infection_samples))
}
```

##  Example -- draw one time series of infection

* red shows estimated infections
* blue shows observations

```{r}
## Estimate total infections from deconvolutions

upscaled <- lapply(decon, FUN = function(df) {
  est_total_inf(df, 
                p_obs = p_obs, 
                obs_colname = 'RL_result',
                n_replicates = 1) 
}
)
  
  
  
upscaled %>% 
  bind_rows(.id = 'rep') %>%
  pivot_longer(-c(time, rep)) %>%
  ggplot()+
  geom_line(aes(x = time, y = value, color = name, group = interaction(name, rep)))+
  geom_line(data = rtdf, aes(x = time, y = incidence))
```

## Wrapper to feed resampled time series of observations into Rt estimator
```{r}
overall_rt_boot_wrapper <- function(
 infection_ests,
 p_obs,
 mean_delay=0,
 ww = 3
){
  

  
  ## Estimate Rt and mrege with the cleaned input data frame
  library(doParallel)
  cl <- makeCluster(parallel::detectCores()-1)
  registerDoParallel(cl)
  est_list <- foreach(inf_col= names(infection_ests)[-1],
                      .packages = 'dplyr','EpiEstim', 'tidyr', 
                      .export = c('get_cori', 'na_to_0', 'parlist')) %dopar% {
                          ins = infection_ests %>% 
                            select(time, eval(inf_col)) 
                   
                            get_cori(ins, 
                              obs_col_name = inf_col, 
                              window = ww, 
                              out_name = 'rt',
                              mean_delay = mean_delay, 
                              SI_mean = parlist$true_mean_SI, ## Rough estimates from Ganyani et al
                              SI_var = parlist$true_var_SI,   
                              wend = F) %>%
                            merge(select(ins, time), by = 'time') 
  }
  stopCluster(cl)
  
  ## For each date, get the median of means, the lower .025 of lower bounds and the upper .975 of upper bounds
  summarized_ests <-  bind_rows(est_list, .id = 'replicate') %>%
    group_by(time) %>%
    ## PHIL - for each replicate, we get a mean, upper and lower CI rt estimate.
    ##    I'm not sure what the best way to aggregate is.
    ##    Here I'm taking the median of means, the lower bound of lower bounds and the upper bound of upper bounds.
    summarise(rt.mean = median(rt.mean, na.rm = TRUE),
              rt.lower = quantile(rt.025, probs = .025, na.rm = TRUE),
              rt.upper = quantile(rt.975, probs = 0.975, na.rm = TRUE))
  
  return(summarized_ests)
  
}


```


## Test bootstrap
```{r}
test_overall_bootstrap <- overall_rt_boot_wrapper(infection_ests = upscaled %>% 
                                                    bind_rows(.id = 'rep') %>% 
                                                    mutate(RL_result = round(RL_result)) %>%
                                                    pivot_wider(id_cols = time, names_from = 'rep', names_prefix = 'infections.', values_from = RL_result),
                        p_obs = p_obs)
```

```{r}
test_overall_bootstrap %>%
  merge(sim_df, by = 'time', all.x = T) %>%
  ggplot()+
  geom_line(aes(x = time, y = rt.mean))+
  geom_ribbon(aes(x = time, ymin = rt.lower, ymax = rt.upper), alpha = .3)+
  geom_hline(aes(yintercept = 1))+
  geom_line( aes(x = time, y = true_rt), color = 'dodgerblue')+
  ylab('Rt')
```

